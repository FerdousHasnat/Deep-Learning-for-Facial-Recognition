{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5342e860-ad55-47f0-a8ef-d50380e23f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # The FER-2013 images are grayscale, so in_channels=1.\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # FER-2013 images are 48x48 pixels, so after two pooling layers, the size will be 12x12.\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)  # 4 classes to classify\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 12 * 12)  # Flatten the layer\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4fc5dfb-b283-45ea-bcf6-0c739cd94434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset: 56.24%\n",
      "Predicted class: surprise\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path):\n",
    "    model = SimpleCNN()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def evaluate_on_dataset(model, dataset_path, transform):\n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on the dataset: {accuracy:.2f}%')\n",
    "\n",
    "def predict_image(model, image_path, transform):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = class_labels[predicted.item()]\n",
    "        \n",
    "    print(f'Predicted class: {predicted_label}')\n",
    "\n",
    "# Test class labels\n",
    "class_labels = {\n",
    "    0: \"engaged\",\n",
    "    1: \"happy\",\n",
    "    2: \"neutral\",\n",
    "    3: \"surprise\"\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:\\\\Users\\\\User\\\\best_model.pth\"\n",
    "    dataset_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\472 project\\\\project 1\\\\COMP-472-Project-main\\\\COMP-472-Project-main\\\\datasets\\\\final_clean\\\\test\"\n",
    "    image_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\472 project\\\\project 1\\\\COMP-472-Project-main\\\\COMP-472-Project-main\\\\datasets\\\\final_clean\\\\test\\\\surprise\\\\PrivateTest_1338609.jpg\"\n",
    "\n",
    "    # transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    evaluate_on_dataset(model, dataset_path, transform)  # Evaluate on the entire \"test\" dataset\n",
    "    predict_image(model, image_path, transform)  # Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b3901-ec53-4431-a532-51482f6eb322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
